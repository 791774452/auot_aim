# ---------------------
# Bilibili: éšé£è€Œæ¯
# Timeï¼š2022/5/5 19:02
# ---------------------
import argparse
import datetime
import math
import os
from concurrent.futures import ThreadPoolExecutor

import pyautogui
import win32api
import platform
import subprocess
import threading
import time
from collections import namedtuple, OrderedDict
from pathlib import Path
from subprocess import check_output
import cv2
import mss
import numpy as np
import pkg_resources as pkg
import pydirectinput
import pandas as pd
import torch
import win32con
from colorama.win32 import windll
from simple_pid.PID import PID
from torch import nn
from pynput.mouse import Button, Controller, Listener
from aim.mydata import letterbox, non_max_suppression, scale_coords, xyxy2xywh, LOGGER
from models.experimental import attempt_load
from utils.torch_utils import time_sync

VERBOSE = str(os.getenv('YOLOv5_VERBOSE', True)).lower() == 'true'  # å…¨å±€è¯¦ç»†æ¨¡å¼
FILE = Path(__file__).resolve()
# æ–‡ä»¶ä½ç½®
ROOT = FILE.parents[0]
# print("ROOT",FILE.parents[0])
MOUSE_STATE = False
AIM_X_Y = (0, 0)
mutex = threading.Lock()


# æŸ¥çœ‹å¼€å§‹æ—¶é—´
def date_modified(path=__file__):
    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'


# githuab
def git_describe(path=Path(__file__).parent):  # è·¯å¾„å¿…é¡»æ˜¯ç›®å½•
    # è¿”å›å¯è¯»çš„ git æè¿°
    s = f'git -C {path} describe --tags --long --always'
    try:
        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]
    except subprocess.CalledProcessError:
        return ''  # ä¸æ˜¯ git å­˜å‚¨åº“


# æŸ¥çœ‹CUDAå’Œpytorchç‰ˆæœ¬
def select_device(device='', batch_size=0, newline=True):
    # device = 'cpu' or '0' or '0,1,2,3'
    s = f'YOLOv5 ğŸš€ {git_describe() or date_modified()} torch {torch.__version__} '  # string
    device = str(device).strip().lower().replace('cuda:', '')  # to string, 'cuda:0' to '0'
    cpu = device == 'cpu'
    # ä½¿ç”¨cpu
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # å¼ºåˆ¶ torch.cuda.is_available() = False
    # ä½¿ç”¨å…¶ä»–è®¾å¤‡
    elif device:
        os.environ['CUDA_VISIBLE_DEVICES'] = device  # è®¾ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨æ–­è¨€is_available() ä¹‹å‰
        assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \
            f"æ— æ•ˆçš„CUDA'--device {device}' è¯·ä½¿ç”¨â€œ--device cpu æˆ–å…¶ä»–è‹±ä¼Ÿè¾¾ CUDA è®¾å¤‡"
    cuda = not cpu and torch.cuda.is_available()
    # æŸ¥çœ‹CUDAæ•°é‡
    if cuda:
        devices = device.split(',') if device else '0'  # range(torch.cuda.device_count())  # i.e. 0,1,6,7
        n = len(devices)  # è®¾å¤‡æ•°é‡
        if n > 1 and batch_size > 0:  # æ£€æŸ¥ batch_size æ˜¯å¦å¯ä»¥è¢« device_count æ•´é™¤
            assert batch_size % n == 0, f'batch-size {batch_size} ä¸æ˜¯ GPU æ•°é‡çš„å€æ•° ,è¯·ä½¿ç”¨{n}'
        space = ' ' * (len(s) + 1)
        for i, d in enumerate(devices):
            p = torch.cuda.get_device_properties(i)
            # æŸ¥çœ‹æ˜¾å­˜å¤§å°
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2:.0f}MiB)\n"
    else:
        s += 'CPU\n'
    if not newline:
        s = s.rstrip()
    LOGGER.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe
    return torch.device('cuda:0' if cuda else 'cpu')


# æ‰“å° argparser å‚æ•°
def print_args(name, opt):
    LOGGER.info(colorstr(f'é¡¹ç›®:{name} \nå‚æ•°:') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))


# åç¼€æ± ,è·å–åç¼€å‡½æ•°è°ƒç”¨
def export_formats():
    # YOLOv5 å¯¼å‡ºæ ¼å¼
    x = [['PyTorch', '-', '.pt'],
         ['ONNX', 'onnx', '.onnx'],
         ['TensorRT', 'engine', '.engine']]
    return pd.DataFrame(x, columns=['Format', 'Argument', 'Suffix'])


# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å¯æ¥å—çš„åç¼€     è·å–åç¼€å‡½æ•°è°ƒç”¨
def check_suffix(file='yolov5s.pt', suffix=('.pt',), msg=''):
    if file and suffix:  # æœ‰è·¯å¾„å’Œ.ptåç¼€
        if isinstance(suffix, str):  # åˆ¤æ–­.ptæ˜¯å¦str
            suffix = [suffix]
        for f in file if isinstance(file, (list, tuple)) else [file]:  # åˆ¤æ–­fileæ˜¯å¦å…ƒç»„,ä¸æ˜¯å°±æ”¹ä¸ºåˆ—è¡¨
            s = Path(f).suffix.lower()  # å°†é¡¹ç›®è·¯å¾„å’Œæ–‡ä»¶åç¼€æ‹¼æ¥ç„¶åè½¬æ¢å­—ç¬¦ä¸²ä¸­æ‰€æœ‰å¤§å†™å­—ç¬¦ä¸ºå°å†™
            if len(s):
                assert s in suffix, f"{msg}{f} å¯æ¥å—çš„åç¼€æ˜¯{suffix}"  # å¦‚æœé¡¹ç›®è·¯å¾„ä¸‹æ²¡æœ‰suffixåç¼€,è¿”å›é”™è¯¯
                # åˆ¤æ–­ä¸€ä¸ªè¡¨è¾¾å¼,ä¸º false çš„æ—¶å€™è§¦å‘å¼‚å¸¸,æ¡ä»¶ä¸æ»¡è¶³ç¨‹åºè¿è¡Œçš„æƒ…å†µä¸‹ç›´æ¥è¿”å›é”™è¯¯,ç¨‹åºä¸­æ­¢
                # f:ç”¨å¤§æ‹¬å· {} è¡¨ç¤ºè¢«æ›¿æ¢å­—æ®µï¼Œå…¶ä¸­ç›´æ¥å¡«å…¥æ›¿æ¢å†…å®¹


# onnxè°ƒç”¨  æ£€æŸ¥å®‰è£…ä¾èµ–è°ƒç”¨
def colorstr(*input):
    # ä¸ºå­—ç¬¦ä¸²ç€è‰² https://en.wikipedia.org/wiki/ANSI_escape_codeï¼Œå³ colorstr('blue', 'hello world')    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string
    # é¢œè‰²å‚æ•°ï¼Œå­—ç¬¦ä¸²
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])
    colors = {'black': '\033[30m',  # åŸºæœ¬é¢œè‰²
              'red': '\033[31m',
              'green': '\033[32m',
              'yellow': '\033[33m',
              'blue': '\033[34m',
              'magenta': '\033[35m',
              'cyan': '\033[36m',
              'white': '\033[37m',
              'bright_black': '\033[90m',  # å½©è‰²
              'bright_red': '\033[91m',
              'bright_green': '\033[92m',
              'bright_yellow': '\033[93m',
              'bright_blue': '\033[94m',
              'bright_magenta': '\033[95m',
              'bright_cyan': '\033[96m',
              'bright_white': '\033[97m',
              'end': '\033[0m',  # æ‚é¡¹
              'bold': '\033[1m',
              'underline': '\033[4m'}
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']


# onnx æ£€æµ‹è°ƒç”¨ # æ£€æŸ¥ç½‘ç»œè¿æ¥
def check_online():
    import socket
    try:
        socket.create_connection(("1.1.1.1", 443), 5)  # æ£€æŸ¥ä¸»æœºå¯è®¿é—®æ€§
        return True
    except OSError:
        return False


# onnxæ£€æŸ¥è°ƒç”¨      è¿”å›ä¸å¹³å°ç›¸å…³çš„è¡¨æƒ…ç¬¦å·å®‰å…¨ç‰ˆæœ¬çš„å­—ç¬¦ä¸²
def emojis(str=''):
    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str


# onnxè°ƒç”¨ ç”¨æ³•ï¼š@try_except è£…é¥°å™¨
def try_except(func):
    # å°è¯•é™¤å¤–åŠŸèƒ½ã€‚ ç”¨æ³•ï¼š@try_except è£…é¥°å™¨
    def handler(*args, **kwargs):
        try:
            func(*args, **kwargs)
        except Exception as e:
            print(e)

    return handler


# onnxè°ƒç”¨    # æ£€æŸ¥å®‰è£…çš„ä¾èµ–é¡¹æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼ˆé€šè¿‡ *.txt æ–‡ä»¶æˆ–åŒ…åˆ—è¡¨ï¼‰
@try_except
def check_requirements(requirements=ROOT / 'requirements.txt', exclude=(), install=True):
    # è®¾ç½®é¢œè‰²å‚æ•°ï¼Œå­—ç¬¦ä¸²
    prefix = colorstr('red', 'bold', 'requirements:')
    # åˆ¤æ–­requirements.txt æ˜¯å¦åœ¨ä¸ºstr
    if isinstance(requirements, (str, Path)):  # requirements.txt file
        file = Path(requirements)
        # åˆ¤æ–­æ˜¯å¦åœ¨è·¯å¾„exists:æŸ¥è¯¢è·¯å¾„æ˜¯å¦å­˜åœ¨
        assert file.exists(), f"{prefix} {file.resolve()} æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥å¤±è´¥ã€‚"
        # å­˜åœ¨,åˆ™æ‰“å¼€requirements.txt
        with file.open() as f:
            # å…ˆåˆ¤æ–­requirements.tæ˜¯å¦å¯ç”¨,Falseåˆ™ç”¨openvino-dev
            requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(f) if x.name not in exclude]
    # å¦åˆ™ä¸ºåˆ—è¡¨æˆ–å…ƒç»„ç±»å‹åŒ…
    else:

        requirements = [x for x in requirements if x not in exclude]  # åº”ä¸ºç±»å‹ 'collections.Iterable'ï¼Œä½†å®é™…ä¸º 'Path'
    n = 0  # åŒ…æ›´æ–°æ•°é‡
    # éå†
    for r in requirements:
        try:
            pkg.require(r)
        except Exception:  # å¦‚æœä¸æ»¡è¶³è¦æ±‚ï¼Œåˆ™ è¿”å›æœªæ‰¾åˆ°åˆ†å‘ æˆ– ç‰ˆæœ¬å†²çª
            s = f"{prefix} {r} æœªæ‰¾åˆ°ï¼Œè¿™æ˜¯YOLOv5è¦æ±‚çš„"
            # æ˜¯å¦æ›´æ–°,é»˜è®¤ä¸ºTrue
            if install:
                LOGGER.info(f"{s}, æ­£åœ¨å°è¯•è‡ªåŠ¨æ›´æ–°...")
                try:
                    # æ£€æŸ¥äº’è”ç½‘è¿æ¥
                    assert check_online(), f"'pip install {r}' å·²è·³è¿‡ï¼ˆåŸå› :äº’è”ç½‘ç¦»çº¿ï¼‰"
                    # å‡çº§
                    LOGGER.info(check_output(f"pip install '{r}'", shell=True).decode())
                    n += 1
                # è¿”å›æœªçŸ¥é”™è¯¯
                except Exception as e:
                    LOGGER.warning(f'{prefix} {e}')
            # æ˜¯å¦æ›´æ–°,False
            else:
                LOGGER.info(f'{s}. è¯·å®‰è£…å¹¶é‡æ–°è¿è¡Œæ‚¨çš„å‘½ä»¤.')

    # å¦‚æœåŒ…(åº“)æ›´æ–°å®Œæˆ
    if n:
        source = file.resolve() if 'file' in locals() else requirements  # locals å‡½æ•°æ›´æ–°å¹¶ä»¥å­—å…¸å½¢å¼è¿”å›å½“å‰å…¨éƒ¨å±€éƒ¨å˜é‡
        s = f"{prefix} {n} åº“{'s' * (n > 1)} æ¯æ›´æ–°ä¸€æ¬¡ {source}\n" \
            f"{prefix} âš ï¸ {colorstr('bold', 'é‡æ–°å¯åŠ¨è¿è¡Œæ—¶æˆ–é‡æ–°è¿è¡Œå‘½ä»¤ä»¥ä½¿æ›´æ–°ç”Ÿæ•ˆ')}\n"
        LOGGER.info(emojis(s))


# tensorrt   # æ£€æŸ¥ç‰ˆæœ¬ä¸æ‰€éœ€ç‰ˆæœ¬
def check_version(current='0.0.0', minimum='0.0.0', name='version ', pinned=False, hard=False, verbose=False):
    # å¯¹æ¯”ç‰ˆæœ¬
    current, minimum = (pkg.parse_version(x) for x in (current, minimum))
    # å¦‚æœç‰ˆæœ¬æ»¡è¶³åå›True
    result = (current == minimum) if pinned else (current >= minimum)  # bool
    # æ‰“å°
    s = f'YOLOv5 è¦æ±‚ {name}{minimum} , ä½†æ˜¯å½“å‰å·²å®‰è£…{name}{current} '  # å­—ç¬¦ä¸²
    if hard:  # é»˜è®¤è·³è¿‡
        assert result, s  # åˆ¤æ–­æ»¡è¶³æœ€ä½è¦æ±‚
    if verbose and not result:  # resultä¸ºTrue
        LOGGER.warning(s)
    return result  # è¿”å›True


# æ£€æŸ¥å›¾åƒå¤§å°
def make_divisible(x, divisor):
    # è¿”å›æœ€æ¥è¿‘çš„ x å¯è¢«é™¤æ•°æ•´é™¤
    if isinstance(divisor, torch.Tensor):
        divisor = int(divisor.max())  # to int
    return math.ceil(x / divisor) * divisor


# ä¸»å‡½æ•°è°ƒç”¨,æ£€æŸ¥å›¾åƒå¤§å°
def check_img_size(imgsz, s=32, floor=0):
    # éªŒè¯å›¾åƒå¤§å°æ˜¯æ¯ä¸ªç»´åº¦ä¸­ stride çš„å€æ•°
    if isinstance(imgsz, int):  # æ•´æ•°ï¼Œå³ img_size=640
        new_size = max(make_divisible(imgsz, int(s)), floor)
    else:  # åˆ—è¡¨å³ img_size=[640, 480]
        new_size = [max(make_divisible(x, int(s)), floor) for x in imgsz]
    if new_size != imgsz:
        LOGGER.warning(f'WARNING: --img-size {imgsz} å¿…é¡»æ˜¯æœ€å¤§æ­¥å¹…çš„å€æ•° {s}, æ›´æ–°åˆ° {new_size}')
    return new_size


# ä¸»ç±»
class DetectMultiBackend(nn.Module):
    # YOLOv5 MultiBackend ç±»ï¼Œç”¨äºåœ¨å„ç§åç«¯è¿›è¡Œ python æ¨ç†
    def __init__(self, weights='yolov5s.pt', device=None):

        super().__init__()
        # åˆ¤æ–­ä¼ å…¥çš„æ˜¯æ¨¡å‹åˆ—è¡¨è¿˜æ˜¯å•æ¨¡å‹,é»˜è®¤ä¸ºå•æ¨¡å‹
        w = str(weights[0] if isinstance(weights, list) else weights)
        # è·å–åç¼€
        pt, onnx, engine = self.model_type(w)
        # åˆ†é…é»˜è®¤å€¼,ä½†æ˜¯strideåé¢ä¼šé‡æ–°å®šä¹‰ é»˜è®¤64,æ— ç”¨,å¯ä»¥åˆ é™¤
        stride, names = 64, [f'class{i}' for i in range(1000)]
        # PyTorch æ¡†æ¶
        if pt:
            # åŠ è½½ptç¥ç»ç½‘ç»œ
            model = attempt_load(weights if isinstance(weights, list) else w, map_location=device)
            # è®¾ç½®æ¨¡å‹æ­¥å¹…,é‡æ–°å®šä¹‰strideä¸º32
            stride = max(int(model.stride.max()), 32)
            # è·å–ç±»å
            names = model.module.names if hasattr(model, 'module') else model.names  # hasattr:åˆ¤æ–­å¯¹è±¡æ˜¯å¦åŒ…å«å¯¹åº”çš„å±æ€§
            # ä¸º to()ã€cpu()ã€cuda()ã€half()   æ˜¾å¼èµ‹å€¼
            self.model = model

        # onnxRuntime æ¡†æ¶
        elif onnx:
            # å®å£°æ˜
            LOGGER.info(f'æ­£åœ¨ä¸º{w}åŠ è½½onnxruntime...')
            # äº§çœ‹cudaæ˜¯å¦å¯ç”¨    False or True
            cuda = torch.cuda.is_available()
            # é€‰æ‹©ä½¿ç”¨onnxruntime-gpuæˆ–è€…onnxruntime
            check_requirements(('onnx', 'onnxruntime-gpu' if cuda else 'onnxruntime'))
            # å¯¼å…¥
            import onnxruntime
            # å¦‚æœcudaå¯ç”¨,æ‰§è¡ŒCUDAæˆ–è€…,cpu,è‹¥cudaä¸å¯ç”¨,ä½¿ç”¨cpuæ‰§è¡Œ
            providers = ['CUDAæ‰§è¡Œ', 'CPUæ‰§è¡Œ'] if cuda else ['CPUæ‰§è¡Œ']
            # åŠ è½½onnxæ¨¡å‹ ,åˆåˆ°äº†ç†Ÿæ‚‰çš„ä¸€å¹•
            session = onnxruntime.InferenceSession(w)

        # TensorRT ,é¡¾åæ€ä¹‰,æœ€æƒ³è¦çš„
        elif engine:
            # å®å£°æ˜
            LOGGER.info(f'æ­£åœ¨ä¸º{w}åŠ è½½TensorRT...')
            # å¯¼å…¥tensorrt
            import tensorrt as trt  # https://developer.nvidia.com/nvidia-tensorrt-download
            # è¦æ±‚TesoroRt >=7.0.0
            check_version(trt.__version__, '7.0.0', hard=True)
            Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))  # namedtupleæ˜¯ç»§æ‰¿è‡ªtupleçš„å­ç±»ã€‚
            # å†™å…¥æ—¥å¿—
            logger = trt.Logger(trt.Logger.INFO)
            # æ‰“å¼€å¼•æ“,å†™å…¥æ¨¡å‹
            with open(w, 'rb') as f, trt.Runtime(logger) as runtime:
                # åŠ è½½æ¨¡å‹
                model = runtime.deserialize_cuda_engine(f.read())
            bindings = OrderedDict()  # å¯¹å­—å…¸å¯¹è±¡ä¸­å…ƒç´ çš„æ’åº
            # éå†æ¨¡å‹????ä¸æ‡‚
            for index in range(model.num_bindings):
                name = model.get_binding_name(index)
                dtype = trt.nptype(model.get_binding_dtype(index))
                shape = tuple(model.get_binding_shape(index))
                data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)
                bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))
            binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())
            context = model.create_execution_context()
            batch_size = bindings['images'].shape[0]
        self.__dict__.update(locals())  # å°†æ‰€æœ‰å˜é‡åˆ†é…ç»™ self

    '''
    æ¨ç†
    '''

    def forward(self, im, augment=False, visualize=False, val=False):
        # YOLOv5 å¤šåç«¯æ¨ç†
        global y
        b, ch, h, w = im.shape  # batch, channel, height, width
        # print(im.shape)
        # PyTorch
        if self.pt:
            # è¿™é‡Œæ‰æ˜¯çœŸæ­£çš„æ¨ç†
            y = self.model(im, augment=augment, visualize=visualize)
            return y

        # ONNX Runtime
        elif self.onnx:
            im = im.cpu().numpy()  # torch to numpy
            y = self.session.run([self.session.get_outputs()[0].name], {self.session.get_inputs()[0].name: im})[0]

        # TensorRT
        elif self.engine:
            assert im.shape == self.bindings['images'].shape, (im.shape, self.bindings['images'].shape)
            self.binding_addrs['images'] = int(im.data_ptr())
            self.context.execute_v2(list(self.binding_addrs.values()))
            y = self.bindings['output'].data
        y = torch.tensor(y)  # if isinstance(y, np.ndarray) else y
        return (y, []) if val else y

    # è·å–åç¼€çš„é™æ€æ–¹æ³•
    @staticmethod
    def model_type(p='path/to/model.pt'):
        # ä»æ¨¡å‹è·¯å¾„è¿”å›æ¨¡å‹ç±»å‹ï¼Œå³ path='path/to/model.onnx' -> type=onnx
        suffixes = list(export_formats().Suffix)  # å¯¼å‡ºåç¼€
        check_suffix(p, suffixes)  # ä¼ å…¥è·¯å¾„,å’Œåç¼€è¯»å–
        print(f'æ”¯æŒæ­¤åç¼€æ¨¡å‹:{suffixes}')
        p = Path(p).name  # æ¶ˆé™¤è·Ÿéšåˆ†éš”ç¬¦
        pt, onnx, engine = (s in p for s in suffixes)  # éå†suffixesåç¼€æ± ,å¦‚æœåœ¨åç¼€æ± æœ‰å¯¹åº”çš„åç¼€å°±èµ‹å€¼
        return pt, onnx, engine


# mssæˆªå›¾

scr = mss.mss()


def grab_screen_mss(monitor):
    return cv2.cvtColor(np.array(scr.grab(monitor)), cv2.COLOR_BGRA2BGR)


def run(weights=ROOT / 'yolov5s.pt',  # æƒé‡è·¯å¾„

        conf_thres=0.65,  # ç½®ä¿¡åº¦
        imgsz=(640, 640),  # inference size (height, width)
        iou_thres=0.45,  # NMS IOUé˜ˆå€¼
        max_det=1000,  # æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ¬¡æ•°
        device='',  # è®¾å¤‡é€‰æ‹©,å³ 0 or 0,1,2,3 or cpu
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # æŒ‰ç±»åˆ«è¿‡æ»¤ï¼š--class 0ï¼Œæˆ–--class 0 2 3
        half=False,  # ä½¿ç”¨ FP16 åŠç²¾åº¦æ¨ç†
        img_size=(640, 640),  # è¾“å…¥å›¾ç‰‡å°ºå¯¸
        region=(1.0, 1.0),  # æˆªå›¾å¤§å°
        resize_window=1,

        ):
    # å¼•å…¥ é¼ æ ‡çŠ¶æ€
    global MOUSE_STATE
    '''åŠ è½½æ¨¡å‹'''
    # è®¾ç½®è®¾å¤‡
    device = select_device(device)  # select_device:cudaæˆ–è€…cpuçš„ä¿¡æ¯,å¦‚æ˜¾å¡åç§°,æ˜¾å¡ç´¢å¼•ç­‰
    # æ ¹æ®æ¨¡å‹ç±»åˆ«åŠ è½½å¼•æ“
    weights = str(weights)  # å°†è·¯å¾„è½¬ä¸ºå­—ç¬¦ä¸²,ä¹Ÿå¯ä»¥ç›´æ¥ç”¨è·¯å¾„,çœ‹è­¦å‘Šä¸çˆ½è€Œå·²
    model = DetectMultiBackend(weights, device=device)
    # èµ‹å€¼
    stride, names, pt, onnx, engine = model.stride, model.names, model.pt, model.onnx, model.engine
    imgsz = check_img_size(imgsz, s=stride)
    '''half'''
    # åŠç²¾åº¦è®¾ç½®
    half &= (pt or onnx or engine) and device.type != 'cpu'  # åªæœ‰CUDAæ‰æ”¯æŒåŠç²¾åº¦
    # ptç²¾åº¦
    if pt:
        model.model.half() if half else model.model.float()  # cpu ä¸ºå•ç²¾åº¦,cudaä¸ºåŠç²¾åº¦

    '''åŠ è½½å›¾ç‰‡'''
    # æˆªå›¾è®¾ç½®

    top_x, top_y, x, y = 0, 0, 1920, 1080  # x,y å±å¹•å¤§å°,topæ˜¯åŸç‚¹
    img0_x, img0_y = int(x * region[0]), int(y * region[1])  # æˆªå›¾çš„å®½é«˜
    top_x, top_y = int(top_x + x // 2 * (1. - region[0])), int(top_y + y // 2 * (1. - region[1]))  # æˆªå›¾åŒºåŸŸçš„åŸç‚¹
    monitor = {'left': top_x, 'top': top_y, 'width': img0_x, 'height': img0_y}

    # æˆªå›¾
    t0 = time.time()
    cv2.namedWindow('å°é¹¿', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('å°é¹¿', int(img0_x * resize_window), int(img0_y * resize_window))
    # pid_x = PID(1, 0.0, 0.00, setpoint=0, sample_time=0.01, output_limits=(-100,100))
    # pid_y = PID(1, 0.2, 1, setpoint=0, sample_time=0.01, output_limits=(-100,100))
    fps = 0
    while True:
        if not cv2.getWindowProperty('å°é¹¿', cv2.WND_PROP_VISIBLE):
            cv2.destroyAllWindows()
            exit('ç¨‹åºç»“æŸ...')
            break
        img0 = grab_screen_mss(monitor)
        img0 = cv2.resize(img0, (img0_x, img0_y))

        # åŠ è½½å•å¼ å›¾ç‰‡
        # img_path = 'imags_14.jpg'
        # img0 = cv2.imread(img_path)
        # img_hw = img0.shape[:2]
        # print(img_hw)

        '''é¢„å¤„ç†'''
        img = letterbox(img0, img_size, stride=stride, auto=False)[0]
        # è½¬tensor
        img = img.transpose((2, 0, 1))[::-1]  # HWC è½¬ CHWï¼ŒBGR è½¬ RGB
        img = np.ascontiguousarray(img)
        # æ”¾å…¥è®¾å¤‡
        img = torch.from_numpy(img).to(device)  #
        # uint8 è½¬ fp16/32
        img = img.half() if half else img.float()
        # å½’ä¸€åŒ–
        img /= 255
        # æ‰©å¤§æ‰¹é‡è°ƒæš—
        if len(img.shape):
            img = img[None]

        t2 = time_sync()

        '''æ¨ç†'''
        if "pt" in weights:
            pred = model(img, augment=False, visualize=False)[0]
        else:
            pred = model(img, augment=False, visualize=False)

        t3 = time_sync()
        '''åå¤„ç†'''
        # NMS
        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)

        # è¿‡ç¨‹é¢„æµ‹
        aims = []
        for i, det in enumerate(pred):  # æ¯å¼ å›¾ç‰‡
            gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]
            if len(det):
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()
                for *xyxy, conf, cls in reversed(det):
                    # bbox:(tag, x_center, y_center, x_width, y_width)
                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # å¾—åˆ°å½’ä¸€åŒ–xywh
                    line = (cls, *xywh)  # å°†æ ‡ç­¾å’Œåæ ‡ä¸€èµ·å†™å…¥
                    aim = ('%g ' * len(line)).rstrip() % line
                    aim = aim.split(' ')
                    # time.sleep(5)
                    aims.append(aim)
                    # print(aims)
            if len(aims):

                # ç»˜åˆ¶æ–¹æ¡†
                for i, det in enumerate(aims):
                    _, x_center, y_center, width, height = det  # å°†deté‡Œçš„æ•°æ®åˆ†è£…åˆ°å‰é¢   rc_x,y  è¡¨ç¤ºå½’åŒ–åçš„æ¯”ä¾‹åæ ‡
                    x_center, width = img0_x * float(x_center), img0_x * float(width)  # (776, 1376)
                    y_center, height = img0_y * float(y_center), img0_y * float(height)
                    top_left = (int(x_center - width / 2.), int(y_center - height / 2.))
                    bottom_right = (int(x_center + width / 2.), int(y_center + height / 2.))
                    color = (0, 255, 0)  # RGB     æ¡†çš„é¢œè‰²

                    # cv2.putText(img0, names[i], top_left, cv2.FONT_HERSHEY_SIMPLEX, 1, (34, 150, 102), 2)  # æ·»åŠ æ ‡ç­¾å
                    # cv2.putText(img0, names[i], top_left, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)  # æ·»åŠ æ ‡ç­¾å
                    cv2.rectangle(img0, top_left, bottom_right, color, thickness=2)  # thicknessä»£è¡¨çº¿æ¡ç²—ç»†
                    # x y ä½ç½®
                    location_x = round((top_left[0] + bottom_right[0]) / 2 + top_x)
                    location_y = round(top_left[1] + (bottom_right[1] - top_left[1]) / 8 + top_y)
                    # ç§»åˆ°é¼ æ ‡
                    if MOUSE_STATE and len(aims) > 0:
                        # è°ƒç”¨pidè‡ªç„
                        auto_aim(location_x, location_y, int(width), i)
                        break

                    # æˆªå›¾ä¿å­˜
                    # if len(aims) > 1 and fps == 60:
                    #     monitor1 = {'left': 427, 'top': 103, 'width': 1143, 'height': 872}
                    #     frame = grab_screen_mss(monitor1)
                    #     print("éœ€è¦ä¿å­˜")
                    #     cv2.imwrite("D:/Downloads/images/" + str(round(time.time())) + ".jpg", frame)
                    #     # cv2.imwrite('savedImage.jpg', frame)
                    #     cv2.waitKey(1)
                    #     fps = 0
                    # if not fps == 60:
                    #     fps = fps + 1

                # ç»˜åˆ¶fps
        cv2.putText(img0, "FPS:{:.1f}".format(1. / (time.time() - t0)), (0, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                    (0, 0, 255), 3)

        # ç»˜åˆ¶æ¨ç†æ—¶é—´
        cv2.putText(img0, "time:({:.3f}s)".format(t3 - t2), (0, 300),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                    (34, 150, 102), 3)
        # æ‰“å°æ¨ç†æ—¶é—´
        # LOGGER.info("æ¨ç†ï¼š({:.3f}s)".format(t3 - t2),)

        t0 = time.time()
        # 2716490456
        cv2.imshow('å°é¹¿', img0)
        cv2.waitKey(1)


def auto_aim(x, y, width, i, ):
    global AIM_X_Y
    coordinate = win32api.GetCursorPos()
    coordinate = (960, 540)
    # è®¾ç½®ç„å‡†èŒƒå›´
    # åœ†å½¢èŒƒå›´
    result = math.sqrt(
        math.pow(
            coordinate[0] -
            x,
            2) +
        math.pow(
            coordinate[1] -
            y,
            2))
    if result < width * 6:
        win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 960, 540, 0, 0)
        AIM_X_Y = (x, y)
        print("ç±»å‹", i, "å®šä½åæ ‡", x, ",", y, "AIM_X_Y", AIM_X_Y)


# PIDç„å‡†
def pid_aim():
    global MOUSE_STATE, AIM_X_Y
    print("PIDçº¿ç¨‹å¯åŠ¨")
    pid_x = PID(0.02, 0.00, 0.00, sample_time=0, output_limits=(-100, 100))  # 0.006
    pid_y = PID(0.02, 0.00, 0.00, sample_time=0, output_limits=(-100, 100))
    # while True:
    #     aim_start = time.time()
    #     if MOUSE_STATE and AIM_X_Y[0] != 0 and AIM_X_Y[1] != 0:
    #         coordinate = win32api.GetCursorPos()
    #         pid_x.setpoint = AIM_X_Y[0]
    #         pid_y.setpoint = AIM_X_Y[1]
    #         x = pid_x(coordinate[0])
    #         y = pid_y(coordinate[1])
    #         print("éœ€æ±‚", AIM_X_Y, "pidçº¿ç¨‹ç§»åŠ¨åˆ°ï¼š", x, y)
    #         win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, math.ceil(x), math.ceil(y), 0, 0)
    while True:
        aim_start = time.time()
        if MOUSE_STATE and AIM_X_Y[0] != 0 and AIM_X_Y[1] != 0:
            # ç§»åŠ¨åˆ°å±å¹•ä¸­å¿ƒ
            # win32api.SetCursorPos((960, 540))
            # é¼ æ ‡å·¦é”®æŒ‰ä¸‹
            # win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)
            pid_x.setpoint = AIM_X_Y[0]
            pid_y.setpoint = AIM_X_Y[1]
            x, y = win32api.GetCursorPos()
            x = pid_x(960)
            y = pid_y(540)
            # if x > 0:
            #     x = math.ceil(x)
            # else:
            #     x = math.floor(x)
            # if y > 0:
            #     y = math.ceil(y)
            # else:
            #     y = math.floor(y)
            print("éœ€æ±‚", AIM_X_Y, "pidçº¿ç¨‹ç§»åŠ¨åˆ°ï¼š", x, y)
            win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, round(x), round(y), 0, 0)
            # win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
            if not MOUSE_STATE or (abs(x) < 1 and abs(y) < 1):
                win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 960, 540, 0, 0)
                win32api.SetCursorPos((960, 540))
                AIM_X_Y = (0, 0)
        else:
            AIM_X_Y = (0, 0)
        sellp_time = (1 - (time.time() - aim_start) * 60) / 60
        if sellp_time > 0:
            time.sleep(sellp_time)
        else:
            time.sleep(0.02)


def parse_opt():
    parser = argparse.ArgumentParser()
    # parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'MODEL/yolov5s.onnx',help='æ¨¡å‹è·¯å¾„,æ”¯æŒpt,onnx,tensorrt')
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'data/best.pt',
                        # parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'data/yolov5s.pt',
                        help='æ¨¡å‹è·¯å¾„,æ”¯æŒpt,onnx,tensorrt')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[416], help='inference size h,w')
    # parser.add_argument('--conf-thres', type=float, default=0.25, help='ç½®ä¿¡åº¦')
    parser.add_argument('--conf-thres', type=float, default=0.55, help='ç½®ä¿¡åº¦')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoUé˜ˆå€¼')
    parser.add_argument('--max-det', type=int, default=1000, help='æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ¬¡æ•°')
    parser.add_argument('--device', default='', help='è®¾å¤‡é€‰æ‹©, 0æˆ–è€…cpu,ç©ºä¸ºè‡ªåŠ¨é€‰æ‹©è®¾å¤‡,cudaä¼˜å…ˆ')
    parser.add_argument('--classes', nargs='+', type=int, help='æŒ‰ç±»åˆ«è¿‡æ»¤ï¼š--class 0ï¼Œæˆ–--class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='ä¸ç±»åˆ«æ— å…³çš„ NMS')
    parser.add_argument('--half', action='store_true', help='ä½¿ç”¨ FP16 åŠç²¾åº¦æ¨ç†')

    # parser.add_argument('--region', type=tuple, default=(1, 1), help='æ£€æµ‹èŒƒå›´ï¼›åˆ†åˆ«ä¸ºæ¨ªå‘å’Œç«–å‘ï¼Œ(1.0, 1.0)è¡¨ç¤ºå…¨å±æ£€æµ‹ï¼Œ')
    parser.add_argument('--region', type=tuple, default=(0.3, 0.3), help='æ£€æµ‹èŒƒå›´ï¼›åˆ†åˆ«ä¸ºæ¨ªå‘å’Œç«–å‘ï¼Œ(1.0, 1.0)è¡¨ç¤ºå…¨å±æ£€æµ‹ï¼Œ')
    parser.add_argument('--resize-window', type=float, default=1 / 2, help='ç¼©æ”¾å®æ—¶æ£€æµ‹çª—å£å¤§å°')
    opt = parser.parse_args()
    # print_args(FILE.stem, opt)
    return opt


def on_click(x, y, button, pressed):
    global MOUSE_STATE, AIM_X_Y
    mutex.acquire()
    # MOUSE_STATE = pressed
    # MOUSE_STATE = True

    if button == Button.right and pressed:
        MOUSE_STATE = not MOUSE_STATE
    mutex.release()
    print('{0} at {1}'.format('æŒ‰ä¸‹Pressed' if pressed else 'æ¾å¼€Released', (x, y)), button, MOUSE_STATE)
    if not pressed:
        AIM_X_Y = (0, 0)


def click_main():
    with Listener(on_click=on_click) as listener:
        listener.join()


def reset():
    global MOUSE_STATE
    while True:
        if MOUSE_STATE:
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
            # ç§»åŠ¨åˆ°å±å¹•ä¸­å¿ƒ
            win32api.SetCursorPos((960, 540))
            # é¼ æ ‡å·¦é”®æŒ‰ä¸‹
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)
            time.sleep(1)


# æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜æƒé™
def is_admin():
    try:
        return windll.shell32.IsUserAnAdmin()
    except OSError as err:
        print('OS error: {0}'.format(err))
        return False


def main(opt):
    pool = ThreadPoolExecutor(max_workers=3)
    check_requirements(exclude=('tensorboard', 'thop'))
    if not is_admin():
        print("è¯·ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ")
        return
    # pool.submit(click_main)
    # pool.submit(run, **vars(opt))
    # print(pool.submit(pid_aim).result())
    # print(pool.submit(run, **vars(opt)).result())

    try:
        pool.submit(click_main)
        # pool.submit(reset)
        pool.submit(run, **vars(opt))
        print(pool.submit(pid_aim).result())
    except Exception as e:
        print('yoloå‡ºç°å¼‚å¸¸:', e)


if __name__ == '__main__':
    opt = parse_opt()
    main(opt)
